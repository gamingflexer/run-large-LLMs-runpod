TheBloke_guanaco-65B-GPTQ$:
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: None
  model_type: llama
  pre_layer: 0
  autogptq: false
  triton: false
  desc_act: false
  threads: 0
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_memory_0: 0
TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ$:
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: None
  model_type: llama
  pre_layer: 0
  autogptq: false
  triton: false
  desc_act: false
  threads: 0
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_memory_0: 0
TheBloke_Samantha-33B-GPTQ$:
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: None
  model_type: llama
  pre_layer: 0
  autogptq: false
  triton: false
  desc_act: false
  threads: 0
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_memory_0: 0
ehartford_WizardLM-30B-Uncensored$:
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: 128
  model_type: flame
  pre_layer: 0
  autogptq: false
  triton: false
  desc_act: false
  threads: 0
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_memory_0: 0
TheBloke_WizardLM-30B-Uncensored-GPTQ$:
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: None
  model_type: llama
  pre_layer: 0
  autogptq: false
  triton: false
  desc_act: false
  threads: 0
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_memory_0: 0
TheBloke_gpt4-alpaca-lora-30B-GPTQ-4bit-128g$:
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: '128'
  model_type: llama
  pre_layer: 0
  autogptq: false
  triton: false
  desc_act: false
  threads: 0
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_memory_0: 0
